{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-02T12:18:16.822665300Z",
     "start_time": "2026-01-02T12:18:16.809971400Z"
    }
   },
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, avg, first\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "DATABASE_USER = os.getenv(\"DATABASE_USER\")\n",
    "DATABASE_PASSWORD = os.getenv(\"DATABASE_PASSWORD\")\n",
    "NODE_IP = '192.168.0.24'\n",
    "\n",
    "# Konfiguracja sesji (z fixem dla Java 21)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T12:18:19.871741600Z",
     "start_time": "2026-01-02T12:18:19.479673200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Cassandra Daily Aggregation\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.datastax.spark:spark-cassandra-connector_2.12:3.5.0\") \\\n",
    "    .config(\"spark.cassandra.connection.host\", NODE_IP) \\\n",
    "    .config(\"spark.cassandra.auth.username\", DATABASE_USER) \\\n",
    "    .config(\"spark.cassandra.auth.password\", DATABASE_PASSWORD) \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"--add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"--add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED\") \\\n",
    "    .getOrCreate()\n"
   ],
   "id": "ab2d145f94e506e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "76a5b1fd188be4ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T12:18:21.887377Z",
     "start_time": "2026-01-02T12:18:21.846675200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Odczyt danych surowych\n",
    "df = spark.read \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .options(table=\"measurements\", keyspace=\"air_quality\") \\\n",
    "    .load()\n",
    "\n"
   ],
   "id": "c0a4af9f51186aec",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T12:18:24.382889600Z",
     "start_time": "2026-01-02T12:18:24.290476800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Przetwarzanie: Konwersja timestamp na datę i grupowanie\n",
    "# first() używamy dla unit i parameter, bo są stałe dla sensora\n",
    "daily_df = df.withColumn(\"day\", to_date(col(\"measure_date\"))) \\\n",
    "    .groupBy(\"station_id\", \"day\") \\\n",
    "    .agg(\n",
    "        avg(\"value\").alias(\"avg_value\"),\n",
    "        first(\"unit\").alias(\"unit\"),\n",
    "        first(\"parameter\").alias(\"parameter\")\n",
    "    )\n",
    "\n",
    "print(\"Wyliczono średnie dzienne. Przykładowe dane:\")\n",
    "daily_df\n"
   ],
   "id": "73aed371cf938fc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyliczono średnie dzienne. Przykładowe dane:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[station_id: string, day: date, avg_value: double, unit: string, parameter: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T12:18:28.948341Z",
     "start_time": "2026-01-02T12:18:27.143209500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 3. Zapis do nowej tabeli\n",
    "try:\n",
    "    daily_df.write \\\n",
    "        .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .options(table=\"daily_averages\", keyspace=\"air_quality\") \\\n",
    "        .save()\n",
    "    print(\"Zapisano średnie do tabeli daily_averages.\")\n",
    "except Exception as e:\n",
    "    print(f\"Błąd podczas zapisu: {e}\")\n",
    "\n",
    "spark.stop()"
   ],
   "id": "bc698638899dfcd0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zapisano średnie do tabeli daily_averages.\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
